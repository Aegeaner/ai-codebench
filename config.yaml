# AI Chat Assistant Configuration

# Conversation settings
conversation:
  history_window_size: 3

# Performance settings
performance:
  enable_context_caching: true
  enable_async_calls: true

# Provider configurations
providers:
  claude:
    # Available models: claude-sonnet-4-5-20250929
    default_model: "claude-sonnet-4-5-20250929"
    knowledge_model: "claude-sonnet-4-5-20250929"
    code_model: "claude-sonnet-4-5-20250929"
    base_url: "https://api.anthropic.com/v1/"

  deepseek:
    # Available models: deepseek-coder, deepseek-chat
    default_model: "deepseek-reasoner"
    knowledge_model: "deepseek-chat"
    code_model: "deepseek-reasoner"
    base_url: "https://api.deepseek.com/"

  gemini:
    # Available models: gemini-flash-latest
    default_model: "gemini-3-pro-preview"
    knowledge_model: "gemini-3-pro-preview"
    code_model: "gemini-3-pro-preview"
    base_url: "https://generativelanguage.googleapis.com/v1beta" # Example for Google API
    max_tokens: 65536

  kimi:
    # Available models: kimi-k2-turbo-preview
    default_model: "kimi-k2-thinking"
    knowledge_model: "kimi-k2-turbo-preview"
    code_model: "kimi-k2-thinking"
    base_url: "https://api.moonshot.cn/v1"

  hunyuan:
    # Available models: hunyuan-3.0
    default_model: "hunyuan-3.0"
    image_model: "hunyuan-3.0"
    base_url: "aiart.eu-frankfurt.tencentcloudapi.com"

  openrouter:
    # Available models: openai/gpt-4o
    default_model: "openai/gpt-4o"
    base_url: "https://openrouter.ai/api/v1"

# Task routing preferences
task_routing:
  # Preferred provider for each task type
  knowledge_provider: "claude" # claude, deepseek, gemini, kimi
  code_provider: "deepseek" # claude, deepseek, gemini, kimi
  image_provider: "gemini" # gemini, hunyuan

  # Fallback order when preferred provider is unavailable
  fallback_order:
    - "claude"
    - "deepseek"
    - "gemini"
    - "kimi"
